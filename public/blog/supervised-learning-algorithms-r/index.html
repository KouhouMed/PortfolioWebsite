<!doctype html>
<html lang="en">
  <head>
  <meta charset="utf-8">
<title>Supervised Learning algorithms with R (part 1) - Mohamed Kouhou&#39;s personal website</title>
<meta name="viewport" content="width=device-width, initial-scale=1">


  <link rel="apple-touch-icon" sizes="180x180" href="/favicon/apple-touch-icon.png?v=1">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon/favicon-32x32.png?v=1">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon/favicon-16x16.png?v=1">
  <link rel="manifest" href="/favicon/site.webmanifest?v=1">
  
    <link rel="mask-icon" href="/favicon/safari-pinned-tab.svg?v=1" color="#ffffff">
    <link rel="shortcut icon" href="/favicon/favicon.ico?v=1">
    <meta name="msapplication-config" content="/favicon/browserconfig.xml?v=1">
  
  <meta name="msapplication-TileColor" content="#ffffff">
  <meta name="theme-color" content="#ffffff">

<meta name="generator" content="Hugo 0.110.0"><meta itemprop="name" content="Supervised Learning algorithms with R (part 1)">
<meta itemprop="description" content="We will discover some of the most common supervised learning algorithms and their implementation with R programming language"><meta itemprop="datePublished" content="2021-01-05T00:00:00+00:00" />
<meta itemprop="dateModified" content="2021-01-05T00:00:00+00:00" />
<meta itemprop="wordCount" content="2270"><meta itemprop="image" content="">
<meta itemprop="keywords" content="machine learning,data science," /><meta property="og:title" content="Supervised Learning algorithms with R (part 1)" />
<meta property="og:description" content="We will discover some of the most common supervised learning algorithms and their implementation with R programming language" />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://kouhoumed.com/blog/supervised-learning-algorithms-r/" /><meta property="og:image" content="" /><meta property="article:section" content="blog" />
<meta property="article:published_time" content="2021-01-05T00:00:00+00:00" />
<meta property="article:modified_time" content="2021-01-05T00:00:00+00:00" />
<meta name="twitter:card" content="summary_large_image"/>
<meta name="twitter:image" content=""/>

<meta name="twitter:title" content="Supervised Learning algorithms with R (part 1)"/>
<meta name="twitter:description" content="We will discover some of the most common supervised learning algorithms and their implementation with R programming language"/>
<meta name="twitter:site" content="@MohamedKouhou"/>
<link rel="stylesheet" href="/css/bundle.min.6ad9eb85bff384c75937a02036b01425a2ca63f19a96535b8ba5b181db62a4b3.css" integrity="sha256-atnrhb/zhMdZN6AgNrAUJaLKY/GallNbi6WxgdtipLM="><link rel="stylesheet" href="/css/add-on.css">
  <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']],
        displayMath: [['$$','$$'], ['\\[', '\\]']],
        processEscapes: true,
        processEnvironments: true
      },
      options: {
        skipHtmlTags: ['script', 'noscript', 'style', 'textarea', 'pre']
      }
    };
  
    window.addEventListener('load', (event) => {
        document.querySelectorAll("mjx-container").forEach(function(x){
          x.parentElement.classList += 'has-jax'})
      });
  
  </script>
  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script type="text/javascript" id="MathJax-script" async
    src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  <link rel="apple-touch-icon" sizes="76x76" href="/apple-touch-icon.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
  <link rel="manifest" href="/site.webmanifest">
  <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
  <meta name="msapplication-TileColor" content="#da532c">
  <meta name="theme-color" content="#ffffff">
</head>

  <body>
    

<header id="site-header">
  <nav id="site-nav">
    <h1 class="nav-title">
      <a href="/" class="nav">
        
          Blog
        
      </a>
    </h1>
    <menu id="site-nav-menu" class="flyout-menu menu">
      
        
          
          <a href="/" class="nav link"><i class='fa fa-home'></i> Home</a>
        
      
        
          
          <a href="/about/" class="nav link"><i class='far fa-id-card'></i> About Me</a>
        
      
        
          
          <a href="/blog/" class="nav link"><i class='far fa-newspaper'></i> Blog</a>
        
      
      <a href="#share-menu" class="nav link share-toggle"><i class="fas fa-share-alt">&nbsp;</i>Share</a>
      <a href="#search-input" class="nav link search-toggle"><i class="fas fa-search">&nbsp;</i>Search</a>
    </menu>
    <a href="#search-input" class="nav search-toggle"><i class="fas fa-search fa-2x">&nbsp;</i></a>
    <a href="#share-menu" class="nav share-toggle"><i class="fas fa-share-alt fa-2x">&nbsp;</i></a>
    
    <a href="#site-nav" class="nav nav-toggle"><i class="fas fa-bars fa-2x"></i></a>
  </nav>
  <menu id="search" class="menu"><input id="search-input" class="search-input menu"></input><div id="search-results" class="search-results menu"></div></menu>
  
  
    <menu id="share-menu" class="flyout-menu menu">
      <h1>Share Post</h1>
      




  
    
    <a href="//twitter.com/share?text=Supervised%20Learning%20algorithms%20with%20R%20%28part%201%29&amp;url=https%3a%2f%2fkouhoumed.com%2fblog%2fsupervised-learning-algorithms-r%2f" target="_blank" rel="noopener" class="nav share-btn twitter">
        <p>Twitter</p>
      </a>
  

  
      <a href="//www.facebook.com/sharer/sharer.php?u=https%3a%2f%2fkouhoumed.com%2fblog%2fsupervised-learning-algorithms-r%2f" target="_blank" rel="noopener" class="nav share-btn facebook">
        <p>Facebook</p>
        </a>
  

  
    <a href="//www.reddit.com/submit?url=https%3a%2f%2fkouhoumed.com%2fblog%2fsupervised-learning-algorithms-r%2f&amp;title=Supervised%20Learning%20algorithms%20with%20R%20%28part%201%29" target="_blank" rel="noopener" class="nav share-btn reddit">
          <p>Reddit</p>
        </a>
  

  
        <a href="//www.linkedin.com/shareArticle?url=https%3a%2f%2fkouhoumed.com%2fblog%2fsupervised-learning-algorithms-r%2f&amp;title=Supervised%20Learning%20algorithms%20with%20R%20%28part%201%29" target="_blank" rel="noopener" class="nav share-btn linkedin">
            <p>LinkedIn</p>
          </a>
  

  
        <a href="//www.pinterest.com/pin/create/button/?url=https%3a%2f%2fkouhoumed.com%2fblog%2fsupervised-learning-algorithms-r%2f&amp;description=Supervised%20Learning%20algorithms%20with%20R%20%28part%201%29" target="_blank" rel="noopener" class="nav share-btn pinterest">
          <p>Pinterest</p>
        </a>
  

  
        <a href="mailto:?subject=Check%20out%20this%20post%20by Mohamed%20Kouhou&amp;body=https%3a%2f%2fkouhoumed.com%2fblog%2fsupervised-learning-algorithms-r%2f" target="_blank" class="nav share-btn email" data-proofer-ignore>
          <p>Email</p>
        </a>
  


    </menu>
  
</header>

    <div id="wrapper">
      <section id="site-intro" >
  <a href="/"><img src="https://kouhoumed.com/images/photo2.jpg" class="circle" width="100" alt="Picture" /></a>
  <header>
    <h1>Mohamed Kouhou</h1>
  </header>
  <main>
    <p>Artificial Intelligence Student at ENSEIRB-MATMECA, Bordeaux INP <br> <strong><a href='https://drive.google.com/file/d/1AGU_13lzD8nbvmhze3XIYZzWvkxzMYdC/view?usp=share_link' style='color : rgb(75, 145, 216)'>→My résumé←</a></strong></p>
  </main>
  
    <footer>
      <ul class="socnet-icons">
        
        <li><a href="//github.com/KouhouMed" target="_blank" rel="noopener" title="GitHub" class="fab fa-github"></a></li>

<li><a href="//stackoverflow.com/users/13006431" target="_blank" rel="noopener" title="Stack Overflow" class="fab fa-stack-overflow"></a></li>








<li><a href="//medium.com/@mohamedkouhou" target="_blank" rel="noopener" title="Medium" class="fab fa-medium"></a></li>
<li><a href="//www.linkedin.com/in/mkouhou/" target="_blank" rel="noopener" title="LinkedIn" class="fab fa-linkedin"></a></li>









<li><a href="//api.whatsapp.com/send?phone=%2b212623159586" target="_blank" rel="noopener" title="WhatsApp" class="fab fa-whatsapp"></a></li>





<li><a href="//twitter.com/MohamedKouhou" target="_blank" rel="noopener" title="Twitter" class="fab fa-twitter"></a></li>











<li><a href="mailto:mohamedkouhou@gmail.com" target="_blank" title="Email" class="far fa-envelope"></a></li>

      </ul>
    </footer>
  
</section>

      <main id="site-main">
        
  <article class="post">
    <header>
  <div class="title">
    
      <h2><a href="/blog/supervised-learning-algorithms-r/">Supervised Learning algorithms with R (part 1)</a></h2>
    
    
      <p>We will discover some of the most common supervised learning algorithms and their implementation with R programming language</p>
    
  </div>
  <div class="meta">
    <time datetime="2021-01-05 00:00:00 &#43;0000 UTC">January 5, 2021</time>
    <p>Mohamed Kouhou</p>
    <p>11-Minute Read</p>
  </div>
</header>

    <div id="socnet-share">
      




  
    
    <a href="//twitter.com/share?text=Supervised%20Learning%20algorithms%20with%20R%20%28part%201%29&amp;url=https%3a%2f%2fkouhoumed.com%2fblog%2fsupervised-learning-algorithms-r%2f" target="_blank" rel="noopener" class="nav share-btn twitter">
        <p>Twitter</p>
      </a>
  

  
      <a href="//www.facebook.com/sharer/sharer.php?u=https%3a%2f%2fkouhoumed.com%2fblog%2fsupervised-learning-algorithms-r%2f" target="_blank" rel="noopener" class="nav share-btn facebook">
        <p>Facebook</p>
        </a>
  

  
    <a href="//www.reddit.com/submit?url=https%3a%2f%2fkouhoumed.com%2fblog%2fsupervised-learning-algorithms-r%2f&amp;title=Supervised%20Learning%20algorithms%20with%20R%20%28part%201%29" target="_blank" rel="noopener" class="nav share-btn reddit">
          <p>Reddit</p>
        </a>
  

  
        <a href="//www.linkedin.com/shareArticle?url=https%3a%2f%2fkouhoumed.com%2fblog%2fsupervised-learning-algorithms-r%2f&amp;title=Supervised%20Learning%20algorithms%20with%20R%20%28part%201%29" target="_blank" rel="noopener" class="nav share-btn linkedin">
            <p>LinkedIn</p>
          </a>
  

  
        <a href="//www.pinterest.com/pin/create/button/?url=https%3a%2f%2fkouhoumed.com%2fblog%2fsupervised-learning-algorithms-r%2f&amp;description=Supervised%20Learning%20algorithms%20with%20R%20%28part%201%29" target="_blank" rel="noopener" class="nav share-btn pinterest">
          <p>Pinterest</p>
        </a>
  

  
        <a href="mailto:?subject=Check%20out%20this%20post%20by Mohamed%20Kouhou&amp;body=https%3a%2f%2fkouhoumed.com%2fblog%2fsupervised-learning-algorithms-r%2f" target="_blank" class="nav share-btn email" data-proofer-ignore>
          <p>Email</p>
        </a>
  


    </div>
    <div class="content">
      <a href="/blog/supervised-learning-algorithms-r/" class="image" style="--bg-image: url('https://i.ibb.co/rFW5Mc2/supervised-learning-r.png');">
    <img class="" src="https://i.ibb.co/rFW5Mc2/supervised-learning-r.png" alt="ml">
  </a>
      <p>As I mentioned in an earlier <a href="https://kouhoumed.site/blog/ml/" >post</a>, machine learning algorithms are categorized into three main types :</p>
<ul>
<li>Supervised learning algorithms</li>
<li>Unsupervised learning algorithms</li>
<li>Reinfocement learning algorithms</li>
</ul>
<p>In this article, we will only talk about some of machine learning supervised algorithms. We&rsquo;ll also see examples using R programming language.</p>
<p>First of all, I would like to remind you that supervised learning is a machine learning algorithm that tries to find a function mapping an input to a given output based on a set of examples. Basically, each of these examples (called <strong>training set</strong>) consists of the input $X$ and the desired output $Y$. In other words, we try to approximate the function $f$ such that $f(X)=Y$ using previously labelled data as learning examples. The performance of such a model is evaluated upon its ability to generalize onto new data that is unlabeled.</p>
<h2 id="k-nearest-neighbours">K-Nearest Neighbours</h2>
<p>K-Nearest Neighbours (KNN) is a simple Machine Learning algorithm based on Supervised Learning technique. It can be used for both regression and classification, but it is mostly used in classification.</p>
<p>Suppose we have two categories : Category $A$ and Category $B$, and we have a new data point $x$ that we want to know to which category it belongs.</p>
<center><img src="https://miro.medium.com/max/800/1*2zYNhLc522h0zftD1zDh2g.png" style="width: 50%;
  height: auto"/></center>
<p>KNN algorithm is comprised of the following steps :</p>
<ul>
<li><strong>Step 1 :</strong> Select K, number of neighbours</li>
<li><strong>Step 2 :</strong> Calculate the distance of between $x$ and each of the other data points (we can use the Euclidian distance or others)</li>
<li><strong>Step 3 :</strong> Take the K nearest neighbors as per the calculated Euclidean distance.</li>
<li><strong>Step 4 :</strong> Among these k neighbors, count the number of the data points in each category.</li>
<li><strong>Step 5 :</strong> Assign the new data points to that category for which the number of the neighbor is maximum.</li>
</ul>
<p><strong>NB 1 :</strong> The Euclidian distance between two points $a_1(x_1,y_1)$ and $a_2(x_2,y_2)$ is calculated as follows : $$d(a_1,a_2)=\sqrt{(x_1-x_2)^2+(y_1-y_2)^2}$$</p>
<center><img src="https://i.ibb.co/DrGLq7q/unnamed.png" style="width: 50%;
  height: auto"/></center>
A more general formula in an n-dimensional space is : $$d(x,y)=\sqrt{\sum_{i=1}^{n}(x_i-y_i)^2}$$ where $x(x_1,...,x_n)$ and $y(y_1,...,y_n)$.
<p><strong>NB 2 :</strong> As can be seen, there are no parameters that need to be learned during training to determine whether a new observation belongs to class  𝐴  or  𝐵.  The only parameter used in K-Nearest Neighbours is K, which is a predetermined value. The algorithm simply works by looking at the training samples, calculating distances and finding the K examples in the training set that are closest to the new observation. Thus, KNN is a <strong>non-parametric</strong>, <strong>supervised</strong> (needs training labels) learning algorithm.</p>
<p><strong>NB 3 :</strong> KNN does  support <a href="https://en.wikipedia.org/wiki/Categorical_variable">categorical variables</a> as features, simply because we cannot calculated the distance from them.</p>
<p>The hands-on example<sup id="fnref:1"><a href="#fn:1" class="footnote-ref" role="doc-noteref">1</a></sup> that we will work on will use the <code>Sonar</code> data set (signals) from <code>mlbench</code> library. <code>Sonar</code> is a system for the detection of objects under water and for measuring the water&rsquo;s depth by emitting and detecting sound pulses (the complete description can be found →<a href="https://cran.r-project.org/web/packages/mlbench/mlbench.pdf">here</a>). For our purposes, this is a two-class (class $R$ and class $M$) classification task with numeric data.</p>
<p>First of all, let&rsquo;s install the required libraries :</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span><span style="color:#75715e"># install the packages (note: this may take some time)</span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">install.packages</span>(<span style="color:#e6db74">&#34;class&#34;</span>)
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">install.packages</span>(<span style="color:#e6db74">&#34;caret&#34;</span>)
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">install.packages</span>(<span style="color:#e6db74">&#34;mlbench&#34;</span>)
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">install.packages</span>(<span style="color:#e6db74">&#34;e1071&#34;</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">library</span>(class)
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">library</span>(caret)
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">require</span>(mlbench)
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">library</span>(e1071)
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">library</span>(base)
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">require</span>(base)
</span></span></code></pre></div><h4 id="step-1--loading-the-data">Step 1 : Loading the data</h4>
<p>Let&rsquo;s load the <code>Sonar</code> dataset and look at the first five rows :</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span><span style="color:#a6e22e">data</span>(Sonar)
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">head</span>(Sonar)
</span></span></code></pre></div><h4 id="step-2--preparing-and-exploring-the-data">Step 2 : Preparing and exploring the data</h4>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span><span style="color:#a6e22e">nrow</span>(Sonar)
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">ncol</span>(Sonar)
</span></span></code></pre></div><p>This will display the number of lines (<em><strong>208 observations</strong></em>) and the number of columns (<em><strong>61 variables</strong></em>), all numerical except for the Class variable which is categorical.</p>
<p>Let&rsquo;s check how many $R$ classes and $M$ classes <code>Sonar</code> contains :</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span>base<span style="color:#f92672">::</span><span style="color:#a6e22e">table</span>(Sonar<span style="color:#f92672">$</span>Class)
</span></span></code></pre></div><p>Now let&rsquo;s see if it contains any <code>NA</code> values in its columns :</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span><span style="color:#a6e22e">apply</span>(Sonar, <span style="color:#ae81ff">2</span>, <span style="color:#a6e22e">function</span>(x) <span style="color:#a6e22e">sum</span>(<span style="color:#a6e22e">is.na</span>(x))) 
</span></span></code></pre></div><p>We are going to manually split <code>Sonar</code> into training and test sets. Here, we will dedicate 70% of the dataset for traing, and the rest for testing :</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span>SEED <span style="color:#f92672">&lt;-</span> <span style="color:#ae81ff">123</span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">set.seed</span>(SEED)
</span></span><span style="display:flex;"><span>data <span style="color:#f92672">&lt;-</span> Sonar[base<span style="color:#f92672">::</span><span style="color:#a6e22e">sample</span>(<span style="color:#a6e22e">nrow</span>(Sonar)), ] <span style="color:#75715e"># shuffle data first</span>
</span></span><span style="display:flex;"><span>bound <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">floor</span>(<span style="color:#ae81ff">0.7</span> <span style="color:#f92672">*</span> <span style="color:#a6e22e">nrow</span>(data))
</span></span><span style="display:flex;"><span>df_train <span style="color:#f92672">&lt;-</span> data[1<span style="color:#f92672">:</span>bound, ] 
</span></span><span style="display:flex;"><span>df_test <span style="color:#f92672">&lt;-</span> data<span style="color:#a6e22e">[</span>(bound <span style="color:#f92672">+</span> <span style="color:#ae81ff">1</span>)<span style="color:#f92672">:</span><span style="color:#a6e22e">nrow</span>(data), ]
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">cat</span>(<span style="color:#e6db74">&#34;Number of training and test samples are &#34;</span>, <span style="color:#a6e22e">nrow</span>(df_train), <span style="color:#a6e22e">nrow</span>(df_test))
</span></span></code></pre></div><p>Now, let&rsquo;s create the following dataframes :</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span>X_train <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">subset</span>(df_train, select<span style="color:#f92672">=-</span>Class)
</span></span><span style="display:flex;"><span>y_train <span style="color:#f92672">&lt;-</span> df_train<span style="color:#f92672">$</span>Class
</span></span><span style="display:flex;"><span>X_test <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">subset</span>(df_test, select<span style="color:#f92672">=-</span>Class) <span style="color:#75715e"># exclude Class for prediction</span>
</span></span><span style="display:flex;"><span>y_test <span style="color:#f92672">&lt;-</span> df_test<span style="color:#f92672">$</span>Class
</span></span></code></pre></div><h4 id="tep-3--training-a-model-on-data">tep 3 : Training a model on data</h4>
<p>Now, we are going to use <code>knn</code> function from <code>class</code> library with  $K=3$ :</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span>knn_model <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">knn</span>(train<span style="color:#f92672">=</span>X_train,
</span></span><span style="display:flex;"><span>                 test<span style="color:#f92672">=</span>X_test,
</span></span><span style="display:flex;"><span>                 cl<span style="color:#f92672">=</span>y_train,  <span style="color:#75715e"># class labels</span>
</span></span><span style="display:flex;"><span>                 k<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>)
</span></span><span style="display:flex;"><span>knn_model
</span></span></code></pre></div><p>If you run the code above, you&rsquo;ll see the prediction made by <code>knn_model</code> with $K=3$ on <code>X_test</code>.</p>
<h4 id="step-4--evaluate-the-model-performance">Step 4 : Evaluate the model performance</h4>
<p>In order to see how many classes have been correctly or incorrectly classified, we can create a <strong><a href="https://en.wikipedia.org/wiki/Confusion_matrix">confusion matrix</a></strong> as follows :</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span>conf_mat <span style="color:#f92672">&lt;-</span> base<span style="color:#f92672">::</span><span style="color:#a6e22e">table</span>(y_test, knn_model)
</span></span><span style="display:flex;"><span>conf_mat
</span></span></code></pre></div><p>To compute the <strong><a href="https://en.wikipedia.org/wiki/Accuracy_and_precision">accuracy</a></strong>, we sum up all the correctly classified observations (located in diagonal) and divide it by the total number of classes :</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span><span style="color:#a6e22e">cat</span>(<span style="color:#e6db74">&#34;Accuracy: &#34;</span>, <span style="color:#a6e22e">sum</span>(<span style="color:#a6e22e">diag</span>(conf_mat))<span style="color:#f92672">/</span><span style="color:#a6e22e">sum</span>(conf_mat))
</span></span></code></pre></div><p>To assess whether $K=3$ is a good choice and see whether $K=3$ leads to <a href="https://machinelearningmastery.com/overfitting-and-underfitting-with-machine-learning-algorithms/">overfitting/underfitting</a> the data, we could use <code>knn.cv</code> which does the <strong>leave-one-out cross-validations</strong> for training set (i.e., it singles out a training sample one at a time and tries to view it as a new example and see what class label it assigns).</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span>knn_loocv <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">knn.cv</span>(train<span style="color:#f92672">=</span>X_train, cl<span style="color:#f92672">=</span>y_train, k<span style="color:#f92672">=</span><span style="color:#ae81ff">3</span>)
</span></span><span style="display:flex;"><span>knn_loocv
</span></span></code></pre></div><p>Let&rsquo;s create a confusion matrix to compute the accuracy of the training labels <code>y_train</code> and the cross-validated predictions <code>knn_loocv</code>, same as the above :</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span>conf_mat_cv <span style="color:#f92672">&lt;-</span> base<span style="color:#f92672">::</span><span style="color:#a6e22e">table</span>(y_train, knn_loocv)
</span></span><span style="display:flex;"><span>conf_mat_cv
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">cat</span>(<span style="color:#e6db74">&#34;LOOCV accuracy: &#34;</span>, <span style="color:#a6e22e">sum</span>(<span style="color:#a6e22e">diag</span>(conf_mat_cv)) <span style="color:#f92672">/</span> <span style="color:#a6e22e">sum</span>(conf_mat_cv))
</span></span></code></pre></div><p>The difference between the cross-validated accuracy and the test accuracy shows that $K=3$ leads to overfitting. Perhaps we should change $K$ to lessen the overfitting.</p>
<h4 id="step-5--improve-the-performance-of-the-model">Step 5 : Improve the performance of the model</h4>
<p>There are a couple things we can do in order to improve the performance of our model :</p>
<ul>
<li><strong>Centering and scaling data</strong> : these are forms of preprocessing numerical data (not suitable for categorical data). Centering a variable means subtracting the mean of the variable from each data point so that the new variable&rsquo;s mean is 0. And scaling consists of multiplying each data point by a constant in order to alter the range of the data.</li>
<li><strong>Performing a <em>cross-vaidation</em></strong> : this consists of dividing the data into a finite number of subsets. Through each iteration, a subset is set aside, and the remaining subsets are used as the training set. The subset that was set aside is used as the test set (prediction). We will use <code>caret</code> library for this purpose.</li>
</ul>
<p>This is a method of cross-referencing the model built using its own data :</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span>SEED <span style="color:#f92672">&lt;-</span> <span style="color:#ae81ff">2016</span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">set.seed</span>(SEED)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># create the training data 70% of the overall Sonar data.</span>
</span></span><span style="display:flex;"><span>in_train <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">createDataPartition</span>(Sonar<span style="color:#f92672">$</span>Class, p<span style="color:#f92672">=</span><span style="color:#ae81ff">0.7</span>, list<span style="color:#f92672">=</span><span style="color:#66d9ef">FALSE</span>) <span style="color:#75715e"># create training indices</span>
</span></span><span style="display:flex;"><span>ndf_train <span style="color:#f92672">&lt;-</span> Sonar[in_train, ]
</span></span><span style="display:flex;"><span>ndf_test <span style="color:#f92672">&lt;-</span> Sonar[<span style="color:#f92672">-</span>in_train, ]
</span></span></code></pre></div><p>Here, we specify the cross-validation method we want to use to find the best $K$ in grid search.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span><span style="color:#75715e"># lets create a function setup to do 5-fold cross-validation with 2 repeat.</span>
</span></span><span style="display:flex;"><span>ctrl <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">trainControl</span>(method<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;repeatedcv&#34;</span>, number<span style="color:#f92672">=</span><span style="color:#ae81ff">5</span>, repeats<span style="color:#f92672">=</span><span style="color:#ae81ff">2</span>)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>nn_grid <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">expand.grid</span>(k<span style="color:#f92672">=</span><span style="color:#a6e22e">c</span>(<span style="color:#ae81ff">1</span>,<span style="color:#ae81ff">3</span>,<span style="color:#ae81ff">5</span>,<span style="color:#ae81ff">7</span>))
</span></span><span style="display:flex;"><span>nn_grid
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span><span style="color:#a6e22e">set.seed</span>(SEED)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>best_knn <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">train</span>(Class<span style="color:#f92672">~</span>., data<span style="color:#f92672">=</span>ndf_train,
</span></span><span style="display:flex;"><span>                  method<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;knn&#34;</span>,
</span></span><span style="display:flex;"><span>                  trControl<span style="color:#f92672">=</span>ctrl, 
</span></span><span style="display:flex;"><span>                  preProcess <span style="color:#f92672">=</span> <span style="color:#a6e22e">c</span>(<span style="color:#e6db74">&#34;center&#34;</span>, <span style="color:#e6db74">&#34;scale&#34;</span>),  <span style="color:#75715e"># standardize</span>
</span></span><span style="display:flex;"><span>                  tuneGrid<span style="color:#f92672">=</span>nn_grid)
</span></span><span style="display:flex;"><span>best_knn
</span></span></code></pre></div><p>Running the code above, you&rsquo;ll find out that $K=1$ has the highest accuracy from repeated cross-validation.</p>
<h2 id="decision-trees">Decision Trees</h2>
<p><strong>Decision Trees</strong> are one of the most powerful predictive classification models. They are based on the analysis of a set of data points that describe the type of object we want to classify. A Decision tree is a flowchart like tree structure, where each <strong>internal node</strong> denotes a test on an attribute, each <strong>branch</strong> represents an outcome of the test, and each <strong>leaf node</strong> (terminal node) holds a class label.</p>
<center><img src="https://upload.wikimedia.org/wikipedia/commons/6/66/Champignons_mushrooms_%28950475736%29.jpg" style="width: 50%;
  height: auto"/></center>
<p>In our practical example<sup id="fnref:2"><a href="#fn:2" class="footnote-ref" role="doc-noteref">2</a></sup>, we&rsquo;ll try to classify a set of mushrooms as either <em>edible</em> or <em>poisonous</em> based on features like its cap type, color, odor, shape of its stalk, etc.</p>
<center>
  <figure>
    <img src="https://ibm.box.com/shared/static/ar8rlcoyrs0n0kphj4g4n4rbhe76vpd9.png" style="width: 80%;
  height: auto"/>
    <figcaption>Example of mushroom features and their classification</figcaption>
  </figure>
</center>
<p>The algorithm behind Decision trees uses probabilities. For example, if many mushrooms that have large caps are poisonous, the algorithm will assume that the probability of large-cap mushrooms being poisonous is high. When the model is complete, we have a tree-like structure composed of what are called <strong>decision nodes</strong>, which ask our data point questions about its features, and <strong>leaf nodes</strong>, which tells us what classification the decision tree thinks our data point is.</p>
<center>
  <figure>
    <img src="https://ibm.box.com/shared/static/urnm2onpitt8qz2296mltzcfdn1p040f.png" style="width: 80%;
  height: auto"/>
    <figcaption>Example of a possible Decision Tree describing mushrooms</figaption>
  </figure>
</center>
<p>The goal of a decision tree is to split the dataset on based on attributes. But how to find the best feature in each node to split?</p>
<p>To answer this question, let&rsquo;s first define the <strong>Entropy</strong>.</p>
<p><strong>Entropy</strong> is the amount of information disorder, or the amount of randomness in the data. It is calculated for each node and it depends on how much random data that node contains. In decision tree we are looking for a trees that have smallest entropy in their nodes. The entropy is used to calculate the homogeneity of the samples in that node. If the samples are completely homogeneous the entropy is zero and if the sample is an equally divided it has entropy of one. It means, if all data in a node are either poisonous or edible, then the entropy is zero, but if the half of data are poisonous and other half are edible, then the entropuy is one. In our example, we can calculate the Entropy of our target class using the following formula :</p>
<p>$$Entropy = - p(edible)log(p(edible)) - p(poisonous)log(p(poisonous))$$</p>
<p>Decision trees use another metric on which decisions are based : <strong>Information gain</strong>. We can think of it as the opposite of entropy. The more randomness decreases, the more information we gain, and vice-versa. Thus, while building a  decision tree, we choose the attributes with the highest information gain.
$$\text{Information Gain = entropy(parent) – [average entropy(children)]}$$</p>
<p><strong>Algorithm :</strong></p>
<pre><code>  1. Calculate entropy of the target field (the class label) for whole dataset.
  2. For each attribute:
    - split the dataset on the attribute
    - calculate entropy of the target field on splited dataset, using the attribute values
    - calculate the information gain of the attribute
  3. select the attribute that has the largest informmation gain
  4. Branch the tree using the selected attribute
  5. stop, if it is a node with entropy of 0, otherwise jump to step2
</code></pre>
<h4 id="decision-tree-with-r">Decision tree with R</h4>
<p>We will start by loading the data. We&rsquo;ll use <a href="https://archive.ics.uci.edu/ml/machine-learning-databases/mushroom/">UCI&rsquo;s</a> <code>Mushroom</code> dataset. Since this dataset is not inbuilt into R, we need to download it and load it into R :</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span><span style="color:#a6e22e">download.file</span>(<span style="color:#e6db74">&#34;https://ibm.box.com/shared/static/dpdh09s70abyiwxguehqvcq3dn0m7wve.data&#34;</span>, <span style="color:#e6db74">&#34;mushroom.data&#34;</span>)
</span></span></code></pre></div><p>After downloading the file, we need to create a data frame to house the observations in the dataset. Since the dataset is structured using comma-separated values, we can use the <code>read.csv</code> function :</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span>mushrooms <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">read.csv</span>(<span style="color:#e6db74">&#34;mushroom.data&#34;</span>, header <span style="color:#f92672">=</span> F)
</span></span><span style="display:flex;"><span>mushrooms
</span></span></code></pre></div><p>Once that&rsquo;s done, we have the data loaded up. However, the way that it is structured isn&rsquo;t the most intuitive. In the code cell below, we are adding the column names to the data frame with the <code>colnames</code> function. Additionally, since our data frame is composed of factors, we can rename some of these factors to something more easily understood by us using <code>levels</code>.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span><span style="color:#75715e"># Define column names for the mushrooms data frame.</span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">colnames</span>(mushrooms) <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">c</span>(<span style="color:#e6db74">&#34;Class&#34;</span>,<span style="color:#e6db74">&#34;cap.shape&#34;</span>,<span style="color:#e6db74">&#34;cap.surface&#34;</span>,<span style="color:#e6db74">&#34;cap.color&#34;</span>,<span style="color:#e6db74">&#34;bruises&#34;</span>,<span style="color:#e6db74">&#34;odor&#34;</span>,<span style="color:#e6db74">&#34;gill.attachment&#34;</span>,<span style="color:#e6db74">&#34;gill.spacing&#34;</span>,
</span></span><span style="display:flex;"><span>                         <span style="color:#e6db74">&#34;gill.size&#34;</span>,<span style="color:#e6db74">&#34;gill.color&#34;</span>,<span style="color:#e6db74">&#34;stalk.shape&#34;</span>,<span style="color:#e6db74">&#34;stalk.root&#34;</span>,<span style="color:#e6db74">&#34;stalk.surface.above.ring&#34;</span>,
</span></span><span style="display:flex;"><span>                         <span style="color:#e6db74">&#34;stalk.surface.below.ring&#34;</span>,<span style="color:#e6db74">&#34;stalk.color.above.ring&#34;</span>,<span style="color:#e6db74">&#34;stalk.color.below.ring&#34;</span>,<span style="color:#e6db74">&#34;veil.type&#34;</span>,<span style="color:#e6db74">&#34;veil.color&#34;</span>,
</span></span><span style="display:flex;"><span>                         <span style="color:#e6db74">&#34;ring.number&#34;</span>,<span style="color:#e6db74">&#34;ring.type&#34;</span>,<span style="color:#e6db74">&#34;print&#34;</span>,<span style="color:#e6db74">&#34;population&#34;</span>,<span style="color:#e6db74">&#34;habitat&#34;</span>)
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">head</span>(mushrooms)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span><span style="color:#75715e"># Define the factor names for &#34;Class&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">levels</span>(mushrooms<span style="color:#f92672">$</span>Class) <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">c</span>(<span style="color:#e6db74">&#34;Edible&#34;</span>,<span style="color:#e6db74">&#34;Poisonous&#34;</span>)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span><span style="color:#75715e"># Define the factor names for &#34;odor&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">levels</span>(mushrooms<span style="color:#f92672">$</span>odor) <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">c</span>(<span style="color:#e6db74">&#34;Almonds&#34;</span>,<span style="color:#e6db74">&#34;Anise&#34;</span>,<span style="color:#e6db74">&#34;Creosote&#34;</span>,<span style="color:#e6db74">&#34;Fishy&#34;</span>,<span style="color:#e6db74">&#34;Foul&#34;</span>,<span style="color:#e6db74">&#34;Musty&#34;</span>,<span style="color:#e6db74">&#34;None&#34;</span>,<span style="color:#e6db74">&#34;Pungent&#34;</span>,<span style="color:#e6db74">&#34;Spicy&#34;</span>)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Define the factor names for &#34;print&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">levels</span>(mushrooms<span style="color:#f92672">$</span>print) <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">c</span>(<span style="color:#e6db74">&#34;Black&#34;</span>,<span style="color:#e6db74">&#34;Brown&#34;</span>,<span style="color:#e6db74">&#34;Buff&#34;</span>,<span style="color:#e6db74">&#34;Chocolate&#34;</span>,<span style="color:#e6db74">&#34;Green&#34;</span>,<span style="color:#e6db74">&#34;Orange&#34;</span>,<span style="color:#e6db74">&#34;Purple&#34;</span>,<span style="color:#e6db74">&#34;White&#34;</span>,<span style="color:#e6db74">&#34;Yellow&#34;</span>)
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">head</span>(mushrooms)
</span></span></code></pre></div><p>Now let&rsquo;s build our model. We are going to use <code>rpart</code> library to create the decision tree, and <code>rpart.plot</code> to visualize it.
But first, install <code>rpart.plot</code> if it&rsquo;s not already installed.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span><span style="color:#a6e22e">install.packages</span>(<span style="color:#e6db74">&#34;rpart&#34;</span>)
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">install.packages</span>(<span style="color:#e6db74">&#34;rpart.plot&#34;</span>)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span><span style="color:#75715e"># Import our required libraries</span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">library</span>(rpart)
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">library</span>(rpart.plot)
</span></span></code></pre></div><p>To create our decision tree model, we can use the <code>rpart</code> function. <code>rpart</code> is simple to use: you provide it a <code>formula</code>, show it the dataset it is supposed to use and choose a method (either &ldquo;class&rdquo; for classification or &ldquo;anova&rdquo; for regression).</p>
<p>A great trick to know when handling very large structured datasets (our dataset has over 20 columns we want to use!) is that in <code>formula</code> declarations, one can use the <code>.</code> operator as a quick way of designating &ldquo;all other columns&rdquo; to R. You can also <code>print</code> the Decision Tree model to retrieve a summary describing it.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span><span style="color:#75715e"># Create a classification decision tree using &#34;Class&#34; as the variable we want to predict and everything else as its predictors.</span>
</span></span><span style="display:flex;"><span>myDecisionTree <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">rpart</span>(Class <span style="color:#f92672">~</span> ., data <span style="color:#f92672">=</span> mushrooms, method <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;class&#34;</span>)
</span></span><span style="display:flex;"><span><span style="color:#75715e"># Print out a summary of our created model.</span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">print</span>(myDecisionTree)
</span></span></code></pre></div><p>Now that we have our model, we can draw it to gain a better understanding of how it is classifying the data points. We can use the <code>rpart.plot</code>function &ndash; a specialized function for plotting trees &ndash; to render our model. This function takes on some parameters for visualizing the tree in different ways &ndash; try changing the type (from 1 to 4) parameter to see what happens!</p>
<p>If you run the code above, you&rsquo;ll see that our decision tree has perfect accuracy when classifying poisonous mushrooms, and almost perfect accuracy when dealing with edible ones.</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span>newCase  <span style="color:#f92672">&lt;-</span> mushrooms[10,<span style="color:#ae81ff">-1</span>]
</span></span><span style="display:flex;"><span>newCase
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span><span style="color:#a6e22e">predict</span>(myDecisionTree, newCase, type <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;class&#34;</span>)
</span></span></code></pre></div><p><strong>Model accuracy :</strong></p>
<p>Let&rsquo;s split our dataset into traing set and test set :</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span><span style="color:#75715e">## 75% of the sample size</span>
</span></span><span style="display:flex;"><span>n <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">nrow</span>(mushrooms)
</span></span><span style="display:flex;"><span>smp_size <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">floor</span>(<span style="color:#ae81ff">0.75</span> <span style="color:#f92672">*</span> n)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">## set the seed to make your partition reproductible</span>
</span></span><span style="display:flex;"><span><span style="color:#a6e22e">set.seed</span>(<span style="color:#ae81ff">123</span>)
</span></span><span style="display:flex;"><span>train_ind <span style="color:#f92672">&lt;-</span> base<span style="color:#f92672">::</span><span style="color:#a6e22e">sample</span>(<span style="color:#a6e22e">c</span>(<span style="color:#ae81ff">1</span><span style="color:#f92672">:</span>n), size <span style="color:#f92672">=</span> smp_size)
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>mushrooms_train <span style="color:#f92672">&lt;-</span> mushrooms[train_ind, ]
</span></span><span style="display:flex;"><span>mushrooms_test <span style="color:#f92672">&lt;-</span> mushrooms[<span style="color:#f92672">-</span>train_ind, ]
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span>newDT <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">rpart</span>(Class <span style="color:#f92672">~</span> ., data <span style="color:#f92672">=</span> mushrooms_train, method <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;class&#34;</span>)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span>result <span style="color:#f92672">&lt;-</span> <span style="color:#a6e22e">predict</span>(newDT, mushrooms_test[,<span style="color:#ae81ff">-1</span>], type <span style="color:#f92672">=</span> <span style="color:#e6db74">&#34;class&#34;</span>)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span><span style="color:#a6e22e">head</span>(result)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span><span style="color:#a6e22e">head</span>(mushrooms_test<span style="color:#f92672">$</span>Class)
</span></span></code></pre></div><div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-r" data-lang="r"><span style="display:flex;"><span>base<span style="color:#f92672">::</span><span style="color:#a6e22e">table</span>(mushrooms_test<span style="color:#f92672">$</span>Class, result)
</span></span></code></pre></div><p>That&rsquo;s it! See you on another cool article :)</p>
<div class="footnotes" role="doc-endnotes">
<hr>
<ol>
<li id="fn:1">
<p>Credit: <a href="https://www.linkedin.com/in/ehsanmkermani">Ehsan M. Kermani</a>&#160;<a href="#fnref:1" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
<li id="fn:2">
<p>Credit: <a href="https://www.linkedin.com/in/saeedaghabozorgi/?originalSubdomain=ca">Saeed Aghabozorgi</a>, <a href="https://www.linkedin.com/in/walter-gomes/">Walter Gomes de Amorim Junior</a>&#160;<a href="#fnref:2" class="footnote-backref" role="doc-backlink">&#x21a9;&#xfe0e;</a></p>
</li>
</ol>
</div>

    </div>
    <footer>
      <div class="stats">
  
    <ul class="categories">
      
        
          <li><a class="article-terms-link" href="/categories/machine-learning/">machine learning</a></li>
        
          <li><a class="article-terms-link" href="/categories/data-science/">data science</a></li>
        
      
    </ul>
  
  
    <ul class="tags">
      
        
          <li><a class="article-terms-link" href="/tags/machine-learning/">machine learning</a></li>
        
          <li><a class="article-terms-link" href="/tags/data-science/">data science</a></li>
        
      
    </ul>
  
</div>

    </footer>
  </article>
  
    
  <article class="post">
    
    <div>
      <h2 id="say-something">Say Something</h2>
        <form id="comment-form" class="new-comment" method="POST">
          
          <h3 class='reply-notice hidden'>
            <span class='reply-name'></span>
          </h3>

          
          <input type="hidden" name="options[entryId]" value="07a2b6da7c47dda6027aebde7f28dffa">
          <input type='hidden' name='fields[replyThread]' value=''>
          <input type='hidden' name='fields[replyID]' value=''>
          <input type='hidden' name='fields[replyName]' value=''>

          
          <input required name='fields[name]' type='text' placeholder='Your Name'>
          <input name='fields[website]' type='text' placeholder='Your Website'>
          <input required name='fields[email]' type='email' placeholder='Your Email'>
          <textarea required name='fields[body]' placeholder='Your Message' rows='10'></textarea>

          
          

          
          <div class='submit-notice'>
            <strong class='submit-notice-text submit-success hidden'>Thanks for your comment! It will be shown on the site once it has been approved.</strong>
            <strong class='submit-notice-text submit-failed hidden'>Sorry, there was an error with your submission. Please make sure all required fields have been completed and try again.</strong>
          </div>

          
          <input type='submit' value='Submit' class='button'>
          <input type='submit' value='Submitted' class='hidden button' disabled>
          <input type='reset' value='Reset' class='button'>
        </form>
    </div>

    
    <div>
      <h2>Comments</h2>
    </div>
  </article>


  
  <div class="pagination">
    
      <a href="/blog/supervised-algorithms-with-r-2/" class="button left"><span>Supervised Learning algorithms with R (part 2)</span></a>
    
    
      <a href="/blog/ml/" class="button right"><span>What is machine learning ?</span></a>
    
  </div>

      </main>
      <section id="site-sidebar">
  
    <section id="recent-posts">
      <header>
        <h1>Recent Posts</h1>
      </header>
      
      <article class="mini-post">
          <a href="/blog/supervised-algorithms-with-r-2/" class="image" style="--bg-image: url('https://i.ibb.co/8D9B0dC/supervised-learning-r-2.png');">
    <img class="" src="https://i.ibb.co/8D9B0dC/supervised-learning-r-2.png" alt="ml with r">
  </a>
        <header>
          <h2><a href="/blog/supervised-algorithms-with-r-2/">Supervised Learning algorithms with R (part 2)</a></h2>
          <time class="published" datetime="2021-01-07 00:00:00 &#43;0000 UTC">January 7, 2021</time>
        </header>
      </article>
      
      <article class="mini-post">
          <a href="/blog/supervised-learning-algorithms-r/" class="image" style="--bg-image: url('https://i.ibb.co/rFW5Mc2/supervised-learning-r.png');">
    <img class="" src="https://i.ibb.co/rFW5Mc2/supervised-learning-r.png" alt="ml">
  </a>
        <header>
          <h2><a href="/blog/supervised-learning-algorithms-r/">Supervised Learning algorithms with R (part 1)</a></h2>
          <time class="published" datetime="2021-01-05 00:00:00 &#43;0000 UTC">January 5, 2021</time>
        </header>
      </article>
      
      <article class="mini-post">
          <a href="/blog/ml/" class="image" style="--bg-image: url('https://blog.st.com/wp-content/uploads/ST16003_shutterstock_680929729-lprbanner.jpg');">
    <img class="" src="https://blog.st.com/wp-content/uploads/ST16003_shutterstock_680929729-lprbanner.jpg" alt="ml">
  </a>
        <header>
          <h2><a href="/blog/ml/">What is machine learning ?</a></h2>
          <time class="published" datetime="2020-12-05 00:00:00 &#43;0000 UTC">December 5, 2020</time>
        </header>
      </article>
      
      
        <footer>
          <a href="/blog/" class="button">See More</a>
        </footer>
      
    </section>
  

  
    

      <section id="categories">
        <header>
          <h1><a href="/categories">Categories</a></h1>
        </header>
        <ul>
          
          
          <li>
              <a href="/categories/data-science/">data-science<span class="count">4</span></a>
          
          <li>
              <a href="/categories/machine-learning/">machine-learning<span class="count">4</span></a>
          
          <li>
              <a href="/categories/blockchain/">blockchain<span class="count">1</span></a>
          
          </li>
        </ul>
      </section>
    
  

  
</section>

      <footer id="site-footer">
  
      <ul class="socnet-icons">
        
        <li><a href="//github.com/KouhouMed" target="_blank" rel="noopener" title="GitHub" class="fab fa-github"></a></li>

<li><a href="//stackoverflow.com/users/13006431" target="_blank" rel="noopener" title="Stack Overflow" class="fab fa-stack-overflow"></a></li>








<li><a href="//medium.com/@mohamedkouhou" target="_blank" rel="noopener" title="Medium" class="fab fa-medium"></a></li>
<li><a href="//www.linkedin.com/in/mkouhou/" target="_blank" rel="noopener" title="LinkedIn" class="fab fa-linkedin"></a></li>









<li><a href="//api.whatsapp.com/send?phone=%2b212623159586" target="_blank" rel="noopener" title="WhatsApp" class="fab fa-whatsapp"></a></li>





<li><a href="//twitter.com/MohamedKouhou" target="_blank" rel="noopener" title="Twitter" class="fab fa-twitter"></a></li>











<li><a href="mailto:mohamedkouhou@gmail.com" target="_blank" title="Email" class="far fa-envelope"></a></li>

      </ul>
  
  <p class="copyright">
    © 2021 Mohamed Kouhou&#39;s personal website
  </p>
</footer>
<a id="back-to-top" href="#" class="fas fa-arrow-up fa-2x"></a>
      <script src="/js/highlight.js"></script>
    
    <script>hljs.initHighlightingOnLoad();</script><script src="/js/bundle.min.54bc02769e1cb62203144d6b8c09b8ab2195473cc8023456886f4cb8dfc95aa0.js" integrity="sha256-VLwCdp4ctiIDFE1rjAm4qyGVRzzIAjRWiG9MuN/JWqA="></script>
    <script src="/js/add-on.js"></script>
    </div>
  </body>
</html>
